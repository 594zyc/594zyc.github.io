---
---

@inproceedings{zhang2020task,
  title={Task-oriented dialog systems that consider multiple appropriate responses under the same context},
  author={Zhang, Yichi and Ou, Zhijian and Yu, Zhou},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={34},
  number={05},
  pages={9604--9611},
  year={2020},
  abbr={AAAI},
  preview={aaai20_fig.png},
  abstract={Conversations have an intrinsic one-to-many property, which means that multiple responses can be appropriate for the same dialog context. In task-oriented dialogs, this property leads to different valid dialog policies towards task completion. However, none of the existing task-oriented dialog generation approaches takes this property into account. We propose a Multi-Action Data Augmentation (MADA) framework to utilize the one-to-many property to generate diverse appropriate dialog responses. Specifically, we first use dialog states to summarize the dialog history, and then discover all possible mappings from every dialog state to its different valid system actions. During dialog system training, we enable the current dialog state to map to all valid system actions discovered in the previous process to create additional state-action pairs. By incorporating these additional pairs, the dialog policy learns a balanced action distribution, which further guides the dialog model to generate diverse responses. Experimental results show that the proposed framework consistently improves dialog policy diversity, and results in improved response diversity and appropriateness. Our model obtains state-of-the-art results on MultiWOZ.},
  bibtex_show={true},
  arxiv={1911.10484},
  pdf={aaai20_damd.pdf},
  code={https://github.com/thu-spmi/damd-multiwoz},
  selected={true}
}

@inproceedings{gao2020paraphrase,
  title={Paraphrase Augmented Task-Oriented Dialog Generation},
  author={Gao, Silin and Zhang, Yichi and Ou, Zhijian and Yu, Zhou},
  booktitle={Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics},
  pages={639--649},
  year={2020},
  abbr={ACL},
  preview={acl20_parg.png},
  abstract={Neural generative models have achieved promising performance on dialog generation tasks if given a huge data set. However, the lack of high-quality dialog data and the expensive data annotation process greatly limit their application in real-world settings. We propose a paraphrase augmented response generation (PARG) framework that jointly trains a paraphrase model and a response generation model to improve the dialog generation performance. We also design a method to automatically construct paraphrase training data set based on dialog state and dialog act labels. PARG is applicable to various dialog generation models, such as TSCP (Lei et al., 2018) and DAMD (Zhang et al., 2019). Experimental results show that the proposed framework improves these state-of-the-art dialog models further on CamRest676 and MultiWOZ. PARG also significantly outperforms other data augmentation methods in dialog generation tasks, especially under low resource settings.},
  bibtex_show={true},
  arxiv={2004.07462},
  pdf={acl20_parg.pdf},
  code={https://github.com/Silin159/PARG},
  selected={true}
}

@inproceedings{zhang2021hierarchical,
  title={Hierarchical Task Learning from Language Instructions with Unified Transformers and Self-Monitoring},
  author={Zhang, Yichi and Chai, Joyce},
  booktitle={Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021},
  pages={4202--4213},
  year={2021},
  abbr={Findings of ACL},
  preview={acl21_hitut.png},
  abstract={Despite recent progress, learning new tasks through language instructions remains an extremely challenging problem. On the ALFRED benchmark for task learning, the published state-of-the-art system only achieves a task success rate of less than 10% in an unseen environment, compared to the human performance of over 90%. To address this issue, this paper takes a closer look at task learning. In a departure from a widely applied end-to-end architecture, we decomposed task learning into three sub-problems: sub-goal planning, scene navigation, and object manipulation; and developed a model HiTUT (stands for Hierarchical Tasks via Unified Transformers) that addresses each sub-problem in a unified manner to learn a hierarchical task structure. On the ALFRED benchmark, HiTUT has achieved the best performance with a remarkably higher generalization ability. In the unseen environment, HiTUT achieves over 160% performance gain in success rate compared to the previous state of the art. The explicit representation of task structures also enables an in-depth understanding of the nature of the problem and the ability of the agent, which provides insight for future benchmark development and evaluation.},
  bibtex_show={true},
  arxiv={2106.03427},
  pdf={acl21_hitut.pdf},
  code={https://github.com/594zyc/HiTUT},
  selected={true}
}

@inproceedings{zhang2020probabilistic,
  title={A Probabilistic End-To-End Task-Oriented Dialog Model with Latent Belief States towards Semi-Supervised Learning},
  author={Zhang, Yichi and Ou, Zhijian and Hu, Min and Feng, Junlan},
  booktitle={Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)},
  pages={9207--9219},
  year={2020},
  abbr={EMNLP},
  preview={emnlp20_labes.png},
  abstract={Structured belief states are crucial for user goal tracking and database query in task-oriented dialog systems. However, training belief trackers often requires expensive turn-level annotations of every user utterance. In this paper we aim at alleviating the reliance on belief state labels in building end-to-end dialog systems, by leveraging unlabeled dialog data towards semi-supervised learning. We propose a probabilistic dialog model, called the LAtent BElief State (LABES) model, where belief states are represented as discrete latent variables and jointly modeled with system responses given user inputs. Such latent variable modeling enables us to develop semi-supervised learning under the principled variational learning framework. Furthermore, we introduce LABES-S2S, which is a copy-augmented Seq2Seq model instantiation of LABES. In supervised experiments, LABES-S2S obtains strong results on three benchmark datasets of different scales. In utilizing unlabeled dialog data, semi-supervised LABES-S2S significantly outperforms both supervised-only and semi-supervised baselines. Remarkably, we can reduce the annotation demands to 50% without performance loss on MultiWOZ.},
  bibtex_show={true},
  arxiv={2009.08115},
  pdf={emnlp20_labes.pdf},
  code={https://github.com/thu-spmi/LABES},
  selected={true},
  video={https://slideslive.com/38939308/a-probabilistic-endtoend-taskoriented-dialog-model-with-latent-belief-states-towards-semisupervised-learning},
}

@inproceedings{wu-etal-2021-alternating,
    title = "Alternating Recurrent Dialog Model with Large-scale Pre-trained Language Models",
    author = "Wu, Qingyang  and
      Zhang, Yichi  and
      Li, Yu  and
      Yu, Zhou",
    editor = "Merlo, Paola  and
      Tiedemann, Jorg  and
      Tsarfaty, Reut",
    booktitle = "Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume",
    month = apr,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.eacl-main.110",
    doi = "10.18653/v1/2021.eacl-main.110",
    pages = "1292--1301",
    abstract = "Existing dialog system models require extensive human annotations and are difficult to generalize to different tasks. The recent success of large pre-trained language models such as BERT and GPT-2 (Devlin et al., 2019; Radford et al., 2019) have suggested the effectiveness of incorporating language priors in down-stream NLP tasks. However, how much pre-trained language models can help dialog response generation is still under exploration. In this paper, we propose a simple, general, and effective framework: Alternating Recurrent Dialog Model (ARDM). ARDM models each speaker separately and takes advantage of the large pre-trained language model. It requires no supervision from human annotations such as belief states or dialog acts to achieve effective conversations. ARDM outperforms or is on par with state-of-the-art methods on two popular task-oriented dialog datasets: CamRest676 and MultiWOZ. Moreover, we can generalize ARDM to more challenging, non-collaborative tasks such as persuasion. In persuasion tasks, ARDM is capable of generating human-like responses to persuade people to donate to a charity.",
    abbr={EACL},
    preview={eacl21_ardm.png},
    bibtex_show={true},
    arxiv={1910.03756},
    pdf={eacl21_ardm.pdf},
    code={https://github.com/qywu/ARDM},
    selected={true}
}