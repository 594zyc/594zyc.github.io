---
layout: about
title: About
permalink: /
subtitle: <b>Ph.D. Candidate</b> ⎟ <b>UMich CSE</b> ⎟ <b>Conversational AI</b> | <b>Embodied AI</b>  | <b>Multi-Modal</b>

profile:
  align: right
  image: UMich_Yichi.jpg
  image_circular: true # crops the image to make it circular
  more_info:

news: true # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
social: false # includes social icons at the bottom of the page
---

Hello! My name is Yichi Zhang, and I am a Ph.D. candidate in Computer Science and Engineering at University of Michigan. I advised by Professor [Joyce Chai](https://web.eecs.umich.edu/~chaijy/) as a member of the [SLED lab](https://sled.eecs.umich.edu/). I am broadly interested in the intersection between conversational and embodied AI research, with a particular focus on language grounding to visual and physical contexts， multi-modal dialog, and 3D embodied decision making. I have won the [1st Amazon Alexa Prize SimBot Challenge](https://www.amazon.science/alexa-prize/simbot-challenge) in 2023 as the team leader of [SEAGULL](https://www.amazon.science/alexa-prize/university-of-michigans-seagull-wins-alexa-prize-simbot-challenge).

Before joining UMich, I obtained my Master’s in Information and Communication Engineering at Tsinghua University in 2020, advised by Professor [Zhijian Ou](http://oa.ee.tsinghua.edu.cn/ouzhijian/). In 2019, I worked with Professor [Zhou Yu](https://www.cs.columbia.edu/~zhouyu/) as a visiting scholar on task-oriented dialog systems. I got my Bachelor’s in Electronic Information Science and Technology from Tsinghua University in 2017. 
