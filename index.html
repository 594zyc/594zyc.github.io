<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Yichi Zhang </title> <meta name="author" content="Yichi Zhang"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/soccer_icon.png?fac9a39e25e42105064d3d52455e4b82"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://594zyc.github.io/"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js?0afe9f0ae161375728f7bcc5eb5b4ab4"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <div class="navbar-brand social"> <a href="mailto:%7A%68%61%6E%67%79%69%63@%75%6D%69%63%68.%65%64%75" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://scholar.google.com/citations?user=xkBBhY8AAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://www.semanticscholar.org/author/46868553" title="Semantic Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-semantic-scholar"></i></a> <a href="https://github.com/594zyc" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a> <a href="https://www.linkedin.com/in/yichi-zhang-354a83128" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin"></i></a> <a href="https://twitter.com/594zyc" title="X" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-x-twitter"></i></a> </div> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">About <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fa-solid fa-moon"></i> <i class="fa-solid fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Yichi</span> Zhang </h1> <p class="desc"><b>Ph.D. Candidate</b> ⎟ <b>UMich CSE</b> ⎟ <b>Conversational AI</b> | <b>Embodied AI</b> | <b>Multi-Modal</b></p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/UMich_Yichi-480.webp 480w,/assets/img/UMich_Yichi-800.webp 800w,/assets/img/UMich_Yichi-1400.webp 1400w," sizes="(min-width: 1000px) 291.0px, (min-width: 576px) 30vw, 95vw" type="image/webp"> <img src="/assets/img/UMich_Yichi.jpg?948f5251b5e4b258cb8fa816cedea401" class="img-fluid z-depth-1 rounded-circle" width="100%" height="auto" alt="UMich_Yichi.jpg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div class="clearfix"> <p>Hello! My name is Yichi Zhang, and I am a Ph.D. candidate in Computer Science and Engineering at University of Michigan. I advised by Professor <a href="https://web.eecs.umich.edu/~chaijy/" rel="external nofollow noopener" target="_blank">Joyce Chai</a> as a member of the <a href="https://sled.eecs.umich.edu/" rel="external nofollow noopener" target="_blank">SLED lab</a>. I am broadly interested in the intersection between conversational and embodied AI research, with a particular focus on language grounding to visual and physical contexts， multi-modal dialog, and 3D embodied decision making. I have won the <a href="https://www.amazon.science/alexa-prize/simbot-challenge" rel="external nofollow noopener" target="_blank">1st Amazon Alexa Prize SimBot Challenge</a> in 2023 as the team leader of <a href="https://www.amazon.science/alexa-prize/university-of-michigans-seagull-wins-alexa-prize-simbot-challenge" rel="external nofollow noopener" target="_blank">SEAGULL</a>.</p> <p>Before joining UMich, I obtained my Master’s in Information and Communication Engineering at Tsinghua University in 2020, advised by Professor <a href="http://oa.ee.tsinghua.edu.cn/ouzhijian/" rel="external nofollow noopener" target="_blank">Zhijian Ou</a>. In 2019, I worked with Professor <a href="https://www.cs.columbia.edu/~zhouyu/" rel="external nofollow noopener" target="_blank">Zhou Yu</a> as a visiting scholar on task-oriented dialog systems. I got my Bachelor’s in Electronic Information Science and Technology from Tsinghua University in 2017.</p> </div> <h2> <a href="/news/" style="color: inherit">News</a> </h2> <div class="news"> <div class="table-responsive"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">Feb 15, 2024</th> <td> I will join <a href="https://research.facebook.com/" rel="external nofollow noopener" target="_blank">Meta Reality Labs</a> to work with <a href="https://shanemoon.com/" rel="external nofollow noopener" target="_blank">Dr. Shane Moon</a> in Summer 2024 as a Research Scientist Intern. Hope to meet new friends in Seattle! </td> </tr> </table> </div> </div> <h2> <a href="/publications/" style="color: inherit">Selected Publications</a> </h2> <div class="publications"> <h2 class="bibliography">2021</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-3"> <div class="abbr"> <abbr class="badge">Findings of ACL</abbr> </div> <div class="preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/acl21_hitut-480.webp 480w,/assets/img/publication_preview/acl21_hitut-800.webp 800w,/assets/img/publication_preview/acl21_hitut-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/acl21_hitut.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="acl21_hitut.png" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> </div> <div id="zhang2021hierarchical" class="col-sm-7"> <div class="title">Hierarchical Task Learning from Language Instructions with Unified Transformers and Self-Monitoring</div> <div class="author"> <em>Yichi Zhang</em>, and Joyce Chai </div> <div class="periodical"> <em>In Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021</em> , 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="http://arxiv.org/abs/2106.03427" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/acl21_hitut.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://github.com/594zyc/HiTUT" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Despite recent progress, learning new tasks through language instructions remains an extremely challenging problem. On the ALFRED benchmark for task learning, the published state-of-the-art system only achieves a task success rate of less than 10% in an unseen environment, compared to the human performance of over 90%. To address this issue, this paper takes a closer look at task learning. In a departure from a widely applied end-to-end architecture, we decomposed task learning into three sub-problems: sub-goal planning, scene navigation, and object manipulation; and developed a model HiTUT (stands for Hierarchical Tasks via Unified Transformers) that addresses each sub-problem in a unified manner to learn a hierarchical task structure. On the ALFRED benchmark, HiTUT has achieved the best performance with a remarkably higher generalization ability. In the unseen environment, HiTUT achieves over 160% performance gain in success rate compared to the previous state of the art. The explicit representation of task structures also enables an in-depth understanding of the nature of the problem and the ability of the agent, which provides insight for future benchmark development and evaluation.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">zhang2021hierarchical</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Hierarchical Task Learning from Language Instructions with Unified Transformers and Self-Monitoring}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhang, Yichi and Chai, Joyce}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{4202--4213}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-3"> <div class="abbr"> <abbr class="badge">EACL</abbr> </div> <div class="preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/eacl21_ardm-480.webp 480w,/assets/img/publication_preview/eacl21_ardm-800.webp 800w,/assets/img/publication_preview/eacl21_ardm-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/eacl21_ardm.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="eacl21_ardm.png" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> </div> <div id="wu-etal-2021-alternating" class="col-sm-7"> <div class="title">Alternating Recurrent Dialog Model with Large-scale Pre-trained Language Models</div> <div class="author"> Qingyang Wu , <em>Yichi Zhang</em>, Yu Li , and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Zhou Yu' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume</em> , Apr 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="http://arxiv.org/abs/1910.03756" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/eacl21_ardm.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://github.com/qywu/ARDM" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Existing dialog system models require extensive human annotations and are difficult to generalize to different tasks. The recent success of large pre-trained language models such as BERT and GPT-2 (Devlin et al., 2019; Radford et al., 2019) have suggested the effectiveness of incorporating language priors in down-stream NLP tasks. However, how much pre-trained language models can help dialog response generation is still under exploration. In this paper, we propose a simple, general, and effective framework: Alternating Recurrent Dialog Model (ARDM). ARDM models each speaker separately and takes advantage of the large pre-trained language model. It requires no supervision from human annotations such as belief states or dialog acts to achieve effective conversations. ARDM outperforms or is on par with state-of-the-art methods on two popular task-oriented dialog datasets: CamRest676 and MultiWOZ. Moreover, we can generalize ARDM to more challenging, non-collaborative tasks such as persuasion. In persuasion tasks, ARDM is capable of generating human-like responses to persuade people to donate to a charity.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">wu-etal-2021-alternating</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Alternating Recurrent Dialog Model with Large-scale Pre-trained Language Models}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Wu, Qingyang and Zhang, Yichi and Li, Yu and Yu, Zhou}</span><span class="p">,</span>
  <span class="na">editor</span> <span class="p">=</span> <span class="s">{Merlo, Paola and Tiedemann, Jorg and Tsarfaty, Reut}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume}</span><span class="p">,</span>
  <span class="na">month</span> <span class="p">=</span> <span class="nv">apr</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">address</span> <span class="p">=</span> <span class="s">{Online}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Association for Computational Linguistics}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://aclanthology.org/2021.eacl-main.110}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.18653/v1/2021.eacl-main.110}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1292--1301}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> <h2 class="bibliography">2020</h2> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-3"> <div class="abbr"> <abbr class="badge">AAAI</abbr> </div> <div class="preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/aaai20_fig-480.webp 480w,/assets/img/publication_preview/aaai20_fig-800.webp 800w,/assets/img/publication_preview/aaai20_fig-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/aaai20_fig.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="aaai20_fig.png" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> </div> <div id="zhang2020task" class="col-sm-7"> <div class="title">Task-oriented dialog systems that consider multiple appropriate responses under the same context</div> <div class="author"> <em>Yichi Zhang</em>, Zhijian Ou , and Zhou Yu </div> <div class="periodical"> <em>In Proceedings of the AAAI Conference on Artificial Intelligence</em> , Apr 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="http://arxiv.org/abs/1911.10484" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/aaai20_damd.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://github.com/thu-spmi/damd-multiwoz" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Conversations have an intrinsic one-to-many property, which means that multiple responses can be appropriate for the same dialog context. In task-oriented dialogs, this property leads to different valid dialog policies towards task completion. However, none of the existing task-oriented dialog generation approaches takes this property into account. We propose a Multi-Action Data Augmentation (MADA) framework to utilize the one-to-many property to generate diverse appropriate dialog responses. Specifically, we first use dialog states to summarize the dialog history, and then discover all possible mappings from every dialog state to its different valid system actions. During dialog system training, we enable the current dialog state to map to all valid system actions discovered in the previous process to create additional state-action pairs. By incorporating these additional pairs, the dialog policy learns a balanced action distribution, which further guides the dialog model to generate diverse responses. Experimental results show that the proposed framework consistently improves dialog policy diversity, and results in improved response diversity and appropriateness. Our model obtains state-of-the-art results on MultiWOZ.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">zhang2020task</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Task-oriented dialog systems that consider multiple appropriate responses under the same context}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhang, Yichi and Ou, Zhijian and Yu, Zhou}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the AAAI Conference on Artificial Intelligence}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{34}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{05}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{9604--9611}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-3"> <div class="abbr"> <abbr class="badge">ACL</abbr> </div> <div class="preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/acl20_parg-480.webp 480w,/assets/img/publication_preview/acl20_parg-800.webp 800w,/assets/img/publication_preview/acl20_parg-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/acl20_parg.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="acl20_parg.png" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> </div> <div id="gao2020paraphrase" class="col-sm-7"> <div class="title">Paraphrase Augmented Task-Oriented Dialog Generation</div> <div class="author"> Silin Gao , <em>Yichi Zhang</em>, Zhijian Ou , and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Zhou Yu' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics</em> , Apr 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="http://arxiv.org/abs/2004.07462" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/acl20_parg.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a href="https://github.com/Silin159/PARG" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Neural generative models have achieved promising performance on dialog generation tasks if given a huge data set. However, the lack of high-quality dialog data and the expensive data annotation process greatly limit their application in real-world settings. We propose a paraphrase augmented response generation (PARG) framework that jointly trains a paraphrase model and a response generation model to improve the dialog generation performance. We also design a method to automatically construct paraphrase training data set based on dialog state and dialog act labels. PARG is applicable to various dialog generation models, such as TSCP (Lei et al., 2018) and DAMD (Zhang et al., 2019). Experimental results show that the proposed framework improves these state-of-the-art dialog models further on CamRest676 and MultiWOZ. PARG also significantly outperforms other data augmentation methods in dialog generation tasks, especially under low resource settings.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">gao2020paraphrase</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Paraphrase Augmented Task-Oriented Dialog Generation}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Gao, Silin and Zhang, Yichi and Ou, Zhijian and Yu, Zhou}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{639--649}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-3"> <div class="abbr"> <abbr class="badge">EMNLP</abbr> </div> <div class="preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/emnlp20_labes-480.webp 480w,/assets/img/publication_preview/emnlp20_labes-800.webp 800w,/assets/img/publication_preview/emnlp20_labes-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/emnlp20_labes.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="emnlp20_labes.png" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> </div> <div id="zhang2020probabilistic" class="col-sm-7"> <div class="title">A Probabilistic End-To-End Task-Oriented Dialog Model with Latent Belief States towards Semi-Supervised Learning</div> <div class="author"> <em>Yichi Zhang</em>, Zhijian Ou , Min Hu , and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? 'Junlan Feng' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)</em> , Apr 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abstract</a> <a href="http://arxiv.org/abs/2009.08115" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="/assets/pdf/emnlp20_labes.pdf" class="btn btn-sm z-depth-0" role="button">PDF</a> <a class="abstract btn btn-sm z-depth-0" role="button">Video</a> <a href="https://github.com/thu-spmi/LABES" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="abstract hidden"> <p>Structured belief states are crucial for user goal tracking and database query in task-oriented dialog systems. However, training belief trackers often requires expensive turn-level annotations of every user utterance. In this paper we aim at alleviating the reliance on belief state labels in building end-to-end dialog systems, by leveraging unlabeled dialog data towards semi-supervised learning. We propose a probabilistic dialog model, called the LAtent BElief State (LABES) model, where belief states are represented as discrete latent variables and jointly modeled with system responses given user inputs. Such latent variable modeling enables us to develop semi-supervised learning under the principled variational learning framework. Furthermore, we introduce LABES-S2S, which is a copy-augmented Seq2Seq model instantiation of LABES. In supervised experiments, LABES-S2S obtains strong results on three benchmark datasets of different scales. In utilizing unlabeled dialog data, semi-supervised LABES-S2S significantly outperforms both supervised-only and semi-supervised baselines. Remarkably, we can reduce the annotation demands to 50% without performance loss on MultiWOZ.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">zhang2020probabilistic</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A Probabilistic End-To-End Task-Oriented Dialog Model with Latent Belief States towards Semi-Supervised Learning}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhang, Yichi and Ou, Zhijian and Hu, Min and Feng, Junlan}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{9207--9219}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> <div class="abstract hidden"> <div style="text-align: center;"> <figure> <iframe src="https://slideslive.com/38939308/a-probabilistic-endtoend-taskoriented-dialog-model-with-latent-belief-states-towards-semisupervised-learning" class="img-fluid rounded z-depth-1" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen width="auto" height="auto"></iframe> </figure> </div> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Yichi Zhang. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script> <script defer src="/assets/js/common.js?da39b660470d1ba6e6b8bf5f37070b6e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>